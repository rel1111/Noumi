{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "id": "4VTaLhx4i7rd",
        "outputId": "6d4e6488-30d3-4029-d83b-b276c650afa8"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mio\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdates\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmdates\u001b[39;00m \u001b[38;5;66;03m# Import for date formatting\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_timeline\u001b[39m(df):\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "# Production Plan Timeline Generator\n",
        "# This script reads an Excel file, processes production data,\n",
        "# and generates a visual timeline as a downloadable image.\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "import io\n",
        "from google.colab import files\n",
        "import matplotlib.dates as mdates # Import for date formatting\n",
        "\n",
        "def generate_timeline(df):\n",
        "    \"\"\"\n",
        "    Processes the production plan data and generates a timeline.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The DataFrame containing the production plan data.\n",
        "\n",
        "    Returns:\n",
        "        A plot object (matplotlib.pyplot) for the generated timeline.\n",
        "    \"\"\"\n",
        "    # Define colors for each task\n",
        "    colors = {\n",
        "        'processing': 'darkgreen',\n",
        "        'wash': 'purple', # Changed wash color to purple\n",
        "        'changeover': 'darkorange'\n",
        "    }\n",
        "\n",
        "    # Initialize a list to hold all tasks for plotting\n",
        "    tasks = []\n",
        "\n",
        "    # Get the start date and time from the first row\n",
        "    try:\n",
        "        start_time_of_week = pd.to_datetime(df.loc[0, 'Date from'])\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing 'Date from' column: {e}. Please ensure it's in a valid date/time format.\")\n",
        "        return\n",
        "\n",
        "    current_time = start_time_of_week\n",
        "\n",
        "    # Read wash duration and gap from the first row and convert to integers\n",
        "    try:\n",
        "        wash_duration_mins = int(df.loc[0, 'Duration'])\n",
        "        wash_gap_mins = int(df.loc[0, 'Gap'])\n",
        "        wash_duration = timedelta(minutes=wash_duration_mins)\n",
        "        gap_duration = timedelta(minutes=wash_gap_mins)\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Warning: Missing wash column: {e}. Wash cycle will not be scheduled.\")\n",
        "        wash_duration = timedelta(minutes=0) # Set wash duration to 0 if columns are missing\n",
        "        gap_duration = timedelta(hours=0) # Set wash gap to 0\n",
        "    except ValueError as e:\n",
        "         print(f\"Warning: Error converting wash duration or gap to integer: {e}. Please ensure 'Duration' and 'Gap' columns contain valid numbers. Wash cycle will not be scheduled.\")\n",
        "         wash_duration = timedelta(minutes=0)\n",
        "         gap_duration = timedelta(hours=0)\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Error reading wash time: {e}. Wash cycle will not be scheduled.\")\n",
        "        wash_duration = timedelta(minutes=0)\n",
        "        gap_duration = timedelta(hours=0)\n",
        "\n",
        "    # Determine the start time for the first wash and initialize last_wash_end_time\n",
        "    first_wash_time = None\n",
        "    try:\n",
        "        first_wash_time = pd.to_datetime(df.loc[0, 'First Wash Time'])\n",
        "        last_wash_end_time = first_wash_time\n",
        "    except KeyError:\n",
        "        print(\"Warning: 'First Wash Time' column not found. Scheduling first wash based on 'Date from' and 'Gap'.\")\n",
        "        last_wash_end_time = start_time_of_week # Initialize last wash end time based on the start of the week if 'First Wash Time' is missing\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Error reading 'First Wash Time': {e}. Scheduling first wash based on 'Date from' and 'Gap'.\")\n",
        "        last_wash_end_time = start_time_of_week # Initialize last wash end time based on the start of the week if 'First Wash Time' has an error\n",
        "\n",
        "    # If a specific first wash time is provided, add it as a task\n",
        "    if first_wash_time and wash_duration > timedelta(minutes=0):\n",
        "         tasks.append({\n",
        "            'start': first_wash_time,\n",
        "            'end': first_wash_time + wash_duration,\n",
        "            'duration_hours': wash_duration.total_seconds() / 3600,\n",
        "            'task': 'wash',\n",
        "            'product': 'Scheduled Wash',\n",
        "            'order': -2 # Use a smaller order to place it before products\n",
        "         })\n",
        "         last_wash_end_time = first_wash_time + wash_duration # Update last_wash_end_time after scheduling the explicit first wash\n",
        "\n",
        "\n",
        "    # Iterate through each row of the DataFrame to build the timeline for products\n",
        "    for i, row in df.iterrows():\n",
        "        product_name = row['product name']\n",
        "        quantity_liters = row['quantity liters']\n",
        "        process_speed = row['process speed per hour']\n",
        "        line_efficiency = row['line efficiency']\n",
        "        change_over_mins = row['Change Over']\n",
        "\n",
        "        # Rule: Changeover time\n",
        "        # The changeover for the current product happens at the start of its slot.\n",
        "        if i > 0:\n",
        "            change_over_duration = timedelta(minutes=change_over_mins)\n",
        "            changeover_end_time = current_time + change_over_duration\n",
        "            remaining_changeover_duration = change_over_duration\n",
        "\n",
        "            # Schedule washes that fall within the changeover period\n",
        "            next_wash_start_time = last_wash_end_time + gap_duration\n",
        "            scheduled_washes_in_changeover = []\n",
        "            while next_wash_start_time < changeover_end_time:\n",
        "                 wash_end_time = next_wash_start_time + wash_duration\n",
        "                 scheduled_washes_in_changeover.append({\n",
        "                    'start': next_wash_start_time,\n",
        "                    'end': wash_end_time\n",
        "                 })\n",
        "                 last_wash_end_time = wash_end_time\n",
        "                 next_wash_start_time = last_wash_end_time + gap_duration\n",
        "\n",
        "            # Check if changeover overlaps with any scheduled wash\n",
        "            changeover_overlaps_with_wash = any(max(current_time, wash['start']) < min(changeover_end_time, wash['end']) for wash in scheduled_washes_in_changeover)\n",
        "\n",
        "            if changeover_overlaps_with_wash:\n",
        "                # If changeover overlaps with a wash, skip the changeover and move current_time to the end of the last overlapping wash\n",
        "                overlapping_washes = [wash for wash in scheduled_washes_in_changeover if max(current_time, wash['start']) < min(changeover_end_time, wash['end'])]\n",
        "                if overlapping_washes:\n",
        "                    last_overlapping_wash_end = max(wash['end'] for wash in overlapping_washes)\n",
        "                    current_time = last_overlapping_wash_end\n",
        "                # Also add the scheduled wash tasks that fell within the original changeover period\n",
        "                for wash in scheduled_washes_in_changeover:\n",
        "                     # Avoid adding the initial explicit first wash again if it was already added\n",
        "                     if 'order' not in wash or wash['order'] != -2:\n",
        "                          tasks.append({\n",
        "                            'start': wash['start'],\n",
        "                            'end': wash['end'],\n",
        "                            'duration_hours': (wash['end'] - wash['start']).total_seconds() / 3600,\n",
        "                            'task': 'wash',\n",
        "                            'product': 'Scheduled Wash',\n",
        "                            'order': -1\n",
        "                         })\n",
        "\n",
        "\n",
        "            else:\n",
        "                # No overlap, add changeover as planned\n",
        "                tasks.append({\n",
        "                    'start': current_time,\n",
        "                    'end': changeover_end_time,\n",
        "                    'duration_hours': change_over_mins / 60,\n",
        "                    'task': 'changeover',\n",
        "                    'product': product_name,\n",
        "                    'order': i # Add order to maintain original sequence\n",
        "                })\n",
        "                current_time = changeover_end_time\n",
        "\n",
        "\n",
        "        # Calculate effective processing speed and total processing time\n",
        "        effective_speed = process_speed * line_efficiency\n",
        "        total_processing_hours = quantity_liters / effective_speed\n",
        "        processing_end_time = current_time + timedelta(hours=total_processing_hours)\n",
        "\n",
        "        # Calculate total overlap time with washes during processing\n",
        "        total_wash_overlap_duration = timedelta(minutes=0)\n",
        "        next_wash_start_time = last_wash_end_time + gap_duration\n",
        "        while next_wash_start_time < processing_end_time + total_wash_overlap_duration: # Check against potential extended end time\n",
        "             wash_end_time = next_wash_start_time + wash_duration\n",
        "             # Check for overlap with the current processing block (considering potential extension)\n",
        "             overlap_start = max(current_time, next_wash_start_time)\n",
        "             overlap_end = min(processing_end_time + total_wash_overlap_duration, wash_end_time)\n",
        "\n",
        "             if overlap_start < overlap_end:\n",
        "                 overlap_duration = overlap_end - overlap_start\n",
        "                 total_wash_overlap_duration += overlap_duration\n",
        "\n",
        "                 # Avoid adding the initial explicit first wash again if it was already added\n",
        "                 if not (first_wash_time and next_wash_start_time == first_wash_time):\n",
        "                     tasks.append({\n",
        "                        'start': next_wash_start_time,\n",
        "                        'end': wash_end_time,\n",
        "                        'duration_hours': wash_duration.total_seconds() / 3600,\n",
        "                        'task': 'wash',\n",
        "                        'product': 'Scheduled Wash',\n",
        "                        'order': -1\n",
        "                     })\n",
        "                 last_wash_end_time = wash_end_time\n",
        "                 next_wash_start_time = last_wash_end_time + gap_duration\n",
        "             else:\n",
        "                # If the next wash doesn't overlap with the current processing block (even with extension),\n",
        "                # break the loop to avoid infinite loop if gap is very large\n",
        "                break\n",
        "\n",
        "\n",
        "        # Extend processing end time by the total wash overlap duration\n",
        "        extended_processing_end_time = processing_end_time + total_wash_overlap_duration\n",
        "\n",
        "        # Add processing segments, breaking for washes\n",
        "        segment_start_time = current_time\n",
        "        # Filter washes that are within the original processing time range for segmenting\n",
        "        scheduled_wash_intervals_for_segmenting = [(wash['start'], wash['end']) for wash in tasks if wash['task'] == 'wash' and max(current_time, wash['start']) < min(processing_end_time, wash['end'])]\n",
        "        scheduled_wash_intervals_for_segmenting.sort()\n",
        "\n",
        "\n",
        "        for wash_start, wash_end in scheduled_wash_intervals_for_segmenting:\n",
        "            # Add processing segment before wash\n",
        "            if segment_start_time < wash_start:\n",
        "                tasks.append({\n",
        "                   'start': segment_start_time,\n",
        "                   'end': wash_start,\n",
        "                   'duration_hours': (wash_start - segment_start_time).total_seconds() / 3600,\n",
        "                   'task': 'processing',\n",
        "                   'product': product_name,\n",
        "                   'order': i\n",
        "               })\n",
        "            segment_start_time = max(segment_start_time, wash_end) # Start next segment after wash\n",
        "\n",
        "        # Add remaining processing segment after any washes, extending to the adjusted end time\n",
        "        if segment_start_time < extended_processing_end_time:\n",
        "             tasks.append({\n",
        "                'start': segment_start_time,\n",
        "                'end': extended_processing_end_time,\n",
        "                'duration_hours': (extended_processing_end_time - segment_start_time).total_seconds() / 3600,\n",
        "                'task': 'processing',\n",
        "                'product': product_name,\n",
        "                'order': i\n",
        "            })\n",
        "\n",
        "        current_time = extended_processing_end_time # Update current_time based on the extended end time\n",
        "\n",
        "\n",
        "    # Create the plot\n",
        "    fig, ax = plt.subplots(figsize=(18, 8)) # Increased figure width\n",
        "    ax.set_facecolor('white') # Set background color to white\n",
        "\n",
        "    y_pos = 0\n",
        "    product_y_positions = {}\n",
        "    product_order = []\n",
        "\n",
        "    # Create a DataFrame from tasks and sort by the 'order' column to maintain original sequence\n",
        "    tasks_df = pd.DataFrame(tasks).sort_values(by='order')\n",
        "\n",
        "    # Get unique products in the original order, placing 'Scheduled Wash' at the top\n",
        "    unique_products_ordered = ['Scheduled Wash'] + [p for p in tasks_df['product'].unique() if p != 'Scheduled Wash']\n",
        "\n",
        "\n",
        "    for product_name in unique_products_ordered:\n",
        "        group = tasks_df[tasks_df['product'] == product_name].sort_values(by='start') # Sort tasks within product by start time\n",
        "        product_y_positions[product_name] = y_pos\n",
        "        product_order.append(product_name)\n",
        "        for _, task in group.iterrows():\n",
        "            ax.broken_barh([(task['start'], task['end'] - task['start'])], (y_pos - 0.4, 0.8),\n",
        "                           facecolors=colors[task['task']], edgecolor='black')\n",
        "            # Add vertical lines from the start and end of each task, extending to the bottom of the plot\n",
        "            ax.vlines(task['start'], ymin=-0.5, ymax=y_pos + 0.4, color='gray', linestyle='-', linewidth=0.5, alpha=0.5) # Adjusted ymin and ymax\n",
        "            ax.vlines(task['end'], ymin=-0.5, ymax=y_pos + 0.4, color='gray', linestyle='-', linewidth=0.5, alpha=0.5) # Adjusted ymin and ymax\n",
        "\n",
        "        y_pos += 1\n",
        "\n",
        "    # Set up the plot aesthetics\n",
        "    ax.set_yticks(list(product_y_positions.values()))\n",
        "    ax.set_yticklabels(product_order) # Use the ordered product names for y-axis labels\n",
        "    ax.set_xlabel(\"Time\")\n",
        "    ax.set_title(\"Weekly Production Plan Timeline\")\n",
        "    ax.grid(True)\n",
        "    ax.invert_yaxis()  # Products at the top (with wash at the very top)\n",
        "\n",
        "    # Format x-axis to show day name and time, and add vertical lines for day divisions\n",
        "    ax.xaxis.set_major_locator(mdates.DayLocator()) # Major ticks at the start of each day\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%a %m-%d')) # Format: AbbreviatedWeekday Month-Day\n",
        "    ax.xaxis.set_minor_locator(mdates.HourLocator(interval=3)) # Minor ticks every 3 hours\n",
        "    ax.xaxis.set_minor_formatter(mdates.DateFormatter('%H:%M')) # Format: Hour:Minute\n",
        "\n",
        "\n",
        "    # Add vertical lines for day divisions\n",
        "    if tasks:\n",
        "        first_date = tasks_df['start'].min().floor('D')\n",
        "        last_date = tasks_df['end'].max().ceil('D')\n",
        "        delta_days = (last_date - first_date).days + 1\n",
        "\n",
        "        for day in range(delta_days):\n",
        "            day_start = first_date + timedelta(days=day)\n",
        "            ax.axvline(day_start, color='gray', linestyle='--', linewidth=1, alpha=0.6) # Added alpha for clarity\n",
        "\n",
        "\n",
        "    # Add time labels for each task start and end time\n",
        "    if tasks:\n",
        "        for _, task in tasks_df.iterrows():\n",
        "            ax.text(task['start'], -0.1, task['start'].strftime('%H:%M'), rotation=90, va='top', ha='right', fontsize=8, fontweight='bold')\n",
        "            ax.text(task['end'], -0.1, task['end'].strftime('%H:%M'), rotation=90, va='top', ha='right', fontsize=8, fontweight='bold')\n",
        "\n",
        "\n",
        "    # Rotate date labels for better readability and move them outside\n",
        "    plt.xticks(rotation=90, ha='right', va='top') # Adjusted alignment for major ticks\n",
        "    plt.setp(ax.get_xminorticklabels(), rotation=90, ha='right', va='top') # Adjusted alignment for minor ticks\n",
        "\n",
        "    # Add small vertical dotted lines at each major and minor tick\n",
        "    ax.tick_params(axis='x', which='both', direction='out', length=6, width=1, colors='gray')\n",
        "\n",
        "\n",
        "    # Create legend\n",
        "    handles = [plt.Rectangle((0, 0), 1, 1, fc=colors[t]) for t in colors]\n",
        "    ax.legend(handles, colors.keys(), loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# Main execution block for Colab\n",
        "print(\"Please upload your Excel file now.\")\n",
        "print(\"The file should contain the following columns:\")\n",
        "print(\"'product name', 'quantity liters', 'process speed per hour', 'line efficiency', 'Change Over', 'Date from', 'Duration', 'Gap', 'First Wash Time'\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    print(\"No file uploaded. Exiting.\")\n",
        "else:\n",
        "    file_name = next(iter(uploaded))\n",
        "    print(f\"File '{file_name}' uploaded successfully.\")\n",
        "\n",
        "    try:\n",
        "        # Read the Excel file into a DataFrame\n",
        "        df = pd.read_excel(io.BytesIO(uploaded[file_name]))\n",
        "        print(\"\\nData loaded:\")\n",
        "        display(df.head())\n",
        "\n",
        "        # Check for required columns\n",
        "        required_columns = ['product name', 'quantity liters', 'process speed per hour', 'line efficiency', 'Change Over', 'Date from', 'Duration', 'Gap', 'First Wash Time']\n",
        "        if not all(col in df.columns for col in required_columns):\n",
        "            missing_cols = [col for col in required_columns if col not in df.columns]\n",
        "            print(f\"\\nError: Missing required columns in the Excel file: {', '.join(missing_cols)}\")\n",
        "        else:\n",
        "            # Generate the timeline plot\n",
        "            fig = generate_timeline(df)\n",
        "\n",
        "            if fig:\n",
        "                output_filename = 'production_timeline.png'\n",
        "                fig.savefig(output_filename, bbox_inches='tight')\n",
        "                print(f\"\\nTimeline generated successfully. Downloading '{output_filename}'...\")\n",
        "                files.download(output_filename)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred during processing: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
