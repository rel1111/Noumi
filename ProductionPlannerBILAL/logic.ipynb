{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6133a721",
   "metadata": {},
   "source": [
    "__Scheduled Washes:__ Run from FIRST WASH TIME then after first_processing_started_after_wash it waits GAP.\n",
    "\n",
    "__Intermediate Washes:__ From first_processing_started_after_wash it waits 24hrs\n",
    "\n",
    "__Processing:__ Runs for [calulation of duration] done via (LE x SPEED TO PRODUCT) / qty to produce, starts from date from and timeline expands a week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50b4564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.dates as mdates\n",
    "import streamlit as st\n",
    "import io\n",
    "\n",
    "\n",
    "test_inputs = []\n",
    "\n",
    "\n",
    "tasks = []\n",
    "\n",
    "\n",
    "\n",
    "#import data, pull all rows into inputs \n",
    "\n",
    "for row in data\n",
    "#init \n",
    "\n",
    "changeover_completed = False\n",
    "wash_active = False\n",
    "first_processing_ticker = True\n",
    "first_processing_time = \n",
    "start_time = pd.to_datetime(df.loc[0,'Date from']) #starting date in csv\n",
    "\n",
    "\n",
    "full_wash_duration\n",
    "#first_processing_check_after_wash should set the ticker to true after every wash, and reset first_processing_time\n",
    "\n",
    "def first_processing_after_wash():\n",
    "    \n",
    "\n",
    "#should check if it runs within the 24hrs from first_processing_after_wash\n",
    "\n",
    "def intermediate_wash(duration):\n",
    "    \n",
    "    z\n",
    "    z\n",
    "\n",
    "#should chekc if its runs within the 54hrs from first_processing_after_wash\n",
    "#should run an intermediate and full wash\n",
    "#should extend processing\n",
    "\n",
    "def full_wash(duration):\n",
    "    x\n",
    "    y\n",
    "    z\n",
    "\n",
    "#should run required changeover for that row, then set changeover_completed to True\n",
    "def changeover(duration):\n",
    "    x\n",
    "    y\n",
    "    z\n",
    "\n",
    "# should set first_processing_ticker to false after setting processing_time\n",
    "# should call change_over completed\n",
    "def processing(duration):\n",
    "    a\n",
    "    b\n",
    "    c\n",
    "\n",
    "def timeline():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83858189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.dates as mdates\n",
    "import streamlit as st\n",
    "import io\n",
    "\n",
    "def generate_timeline(df):\n",
    "    \"\"\"\n",
    "    Processes the production plan data and generates a timeline.\n",
    "    \n",
    "    FIXED: Removes rows with empty/NaN product names before processing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # === FIX: Clean the dataframe first ===\n",
    "    # Remove rows where product name is NaN, empty, or null\n",
    "    df = df.dropna(subset=['product name'])  # Remove rows with NaN product names\n",
    "    df = df[df['product name'].str.strip() != '']  # Remove rows with empty string product names\n",
    "    \n",
    "    # Reset index after filtering\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    st.info(f\"Cleaned data: {len(df)} valid product rows found\")\n",
    "    # =====================================\n",
    "    \n",
    "    # Helper function to safely parse numbers with commas\n",
    "    def safe_number_parse(value, default=0):\n",
    "        try:\n",
    "            if pd.isna(value) or value == '':\n",
    "                return default\n",
    "            # Remove commas and convert to float first, then int\n",
    "            if isinstance(value, str):\n",
    "                clean_value = value.replace(',', '')\n",
    "                return int(float(clean_value))\n",
    "            return int(float(value))\n",
    "        except (ValueError, TypeError):\n",
    "            return default\n",
    "\n",
    "    # colors\n",
    "    colors = {\n",
    "        'processing': 'darkgreen',\n",
    "        'wash': 'purple',\n",
    "        'changeover': 'darkorange',\n",
    "        'intermediate_wash': 'lightblue'\n",
    "    }\n",
    "\n",
    "    tasks = []\n",
    "\n",
    "    # Parse schedule parameters from first row\n",
    "    try:\n",
    "        start_time = pd.to_datetime(df.loc[0, 'Date from'])\n",
    "        \n",
    "        wash_duration_mins = safe_number_parse(df.loc[0, 'Duration'], 0)\n",
    "        wash_gap_mins = safe_number_parse(df.loc[0, 'Gap'], 0)\n",
    "\n",
    "\n",
    "        wash_duration = timedelta(minutes=wash_duration_mins)\n",
    "        gap_duration = timedelta(minutes=wash_gap_mins)\n",
    "\n",
    "        first_wash_time = None\n",
    "        if 'First Wash Time' in df.columns and pd.notna(df.loc[0, 'First Wash Time']):\n",
    "            try:\n",
    "                first_wash_time = pd.to_datetime(df.loc[0, 'First Wash Time'])\n",
    "            except (ValueError, TypeError):\n",
    "                first_wash_time = None\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error parsing schedule parameters: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Intermediate wash duration (3 hours)\n",
    "    intermediate_duration = timedelta(minutes=180)\n",
    "    st.info(f\"Intermediate wash duration: 180 minutes (3 hours)\")\n",
    "\n",
    "    # State trackers\n",
    "    current_time = start_time\n",
    "\n",
    "    last_wash_end_time = first_wash_time + wash_duration\n",
    "\n",
    "    # The time processing STARTED after the last wash. This is the 24-hr origin.\n",
    "    last_processing_start_after_wash = None\n",
    "    reset_24h_on_next_processing = False\n",
    "    reset_duration_on_next_processing = False\n",
    "    \n",
    "    # Global next scheduled wash pointer (runs continuously every wash_duration+gap)\n",
    "    if first_wash_time and wash_duration > timedelta(0):\n",
    "        next_scheduled_wash = first_wash_time + wash_duration + gap_duration\n",
    "    elif wash_duration > timedelta(0):\n",
    "        # no explicit first wash, start counting from schedule start\n",
    "        next_scheduled_wash = start_time + gap_duration\n",
    "    else:\n",
    "        next_scheduled_wash = None\n",
    "\n",
    "    # Add first wash (if specified)\n",
    "    if first_wash_time and wash_duration > timedelta(0):\n",
    "        tasks.append({\n",
    "            'start': first_wash_time,\n",
    "            'end': first_wash_time + wash_duration,\n",
    "            'task': 'wash',\n",
    "            'product': 'Scheduled Wash',\n",
    "            'order': -2\n",
    "        })\n",
    "        tasks.append({\n",
    "            'start': first_wash_time,\n",
    "            'end': first_wash_time + wash_duration,\n",
    "            'task': 'intermediate_wash',\n",
    "            'product': 'Intermediate Wash',\n",
    "            'order': -1\n",
    "        })\n",
    "        last_wash_end_time = first_wash_time + wash_duration\n",
    "        # Update current_time to wait for first wash to complete before starting production\n",
    "        if first_wash_time + wash_duration > current_time:\n",
    "            current_time = first_wash_time + wash_duration + timedelta(minutes=1)  # Add 1 minute buffer\n",
    "        reset_24h_on_next_processing = True\n",
    "\n",
    "    # Helper to compute total extension hours from a list of wash dicts\n",
    "    def total_extension_hours(wash_list):\n",
    "        return sum((w['end'] - w['start']).total_seconds() / 3600.0 for w in wash_list)\n",
    "\n",
    "    # Process products\n",
    "    for i, row in df.iterrows():\n",
    "        product_name = row['product name']\n",
    "        \n",
    "        # Use safe parsing for numeric fields that might have commas\n",
    "        quantity_liters = safe_number_parse(row['quantity liters'], 0)\n",
    "        process_speed = safe_number_parse(row['process speed per hour'], 1)\n",
    "        line_efficiency = float(str(row['line efficiency']).replace(',', '')) if pd.notna(row['line efficiency']) else 0.0\n",
    "        change_over_mins = safe_number_parse(row['Change Over'], 0)\n",
    "        additional_wash = row.get('Additional Wash', 'No') if 'Additional Wash' in row else 'No'\n",
    "\n",
    "        # Insert any scheduled washes that must occur before this product's start time\n",
    "        while next_scheduled_wash and next_scheduled_wash <= current_time:\n",
    "            wash_end = next_scheduled_wash + wash_duration\n",
    "            tasks.append({\n",
    "                'start': next_scheduled_wash,\n",
    "                'end': wash_end,\n",
    "                'task': 'wash',\n",
    "                'product': 'Scheduled Wash',\n",
    "                'order': -2\n",
    "            })\n",
    "            tasks.append({\n",
    "                'start': next_scheduled_wash,\n",
    "                'end': wash_end,\n",
    "                'task': 'intermediate_wash',\n",
    "                'product': 'Intermediate Wash',\n",
    "                'order': -1\n",
    "            })\n",
    "            last_wash_end_time = wash_end\n",
    "            current_time = max(current_time, wash_end + timedelta(minutes=1))  # Add 1 minute buffer after wash\n",
    "            reset_24h_on_next_processing = True\n",
    "            next_scheduled_wash = wash_end + gap_duration\n",
    "\n",
    "        # Additional wash before product (if requested)\n",
    "        additional_wash_end = None\n",
    "        if additional_wash == 'Yes' and wash_duration > timedelta(0):\n",
    "            additional_wash_end = current_time + wash_duration\n",
    "            tasks.append({\n",
    "                'start': current_time,\n",
    "                'end': additional_wash_end,\n",
    "                'task': 'wash',\n",
    "                'product': 'Scheduled Wash',\n",
    "                'order': -2\n",
    "            })\n",
    "            tasks.append({\n",
    "                'start': current_time,\n",
    "                'end': additional_wash_end,\n",
    "                'task': 'intermediate_wash',\n",
    "                'product': 'Intermediate Wash',\n",
    "                'order': -1\n",
    "            })\n",
    "            current_time = additional_wash_end + timedelta(minutes=1)  # Add 1 minute buffer after wash\n",
    "            last_wash_end_time = additional_wash_end\n",
    "            reset_24h_on_next_processing = True\n",
    "\n",
    "        # Changeover (skip for first product)\n",
    "        if i > 0:\n",
    "            changeover_duration = timedelta(minutes=change_over_mins)\n",
    "            changeover_end = current_time + changeover_duration\n",
    "\n",
    "            # If a scheduled wash starts during changeover, prefer the wash\n",
    "            if next_scheduled_wash and next_scheduled_wash < changeover_end and (next_scheduled_wash + wash_duration) > current_time:\n",
    "                wash_end = next_scheduled_wash + wash_duration\n",
    "                tasks.append({\n",
    "                    'start': next_scheduled_wash,\n",
    "                    'end': wash_end,\n",
    "                    'task': 'wash',\n",
    "                    'product': 'Scheduled Wash',\n",
    "                    'order': -2\n",
    "                })\n",
    "                tasks.append({\n",
    "                    'start': next_scheduled_wash,\n",
    "                    'end': wash_end,\n",
    "                    'task': 'intermediate_wash',\n",
    "                    'product': 'Intermediate Wash',\n",
    "                    'order': -1\n",
    "                })\n",
    "                current_time = wash_end + timedelta(minutes=1)  # Add 1 minute buffer after wash\n",
    "                last_wash_end_time = wash_end\n",
    "                reset_24h_on_next_processing = True\n",
    "                next_scheduled_wash = wash_end + gap_duration\n",
    "            elif additional_wash_end and changeover_duration <= wash_duration:\n",
    "                # Changeover fits inside the additional wash (overlap)\n",
    "                changeover_start = additional_wash_end - changeover_duration\n",
    "                tasks.append({\n",
    "                    'start': changeover_start,\n",
    "                    'end': additional_wash_end,\n",
    "                    'task': 'changeover',\n",
    "                    'product': product_name,\n",
    "                    'order': i\n",
    "                })\n",
    "            else:\n",
    "                # Normal changeover\n",
    "                tasks.append({\n",
    "                    'start': current_time,\n",
    "                    'end': changeover_end,\n",
    "                    'task': 'changeover',\n",
    "                    'product': product_name,\n",
    "                    'order': i\n",
    "                })\n",
    "                current_time = changeover_end\n",
    "\n",
    "        # Processing calculation\n",
    "        effective_speed = process_speed * line_efficiency\n",
    "        if effective_speed == 0:\n",
    "            st.error(f\"Effective speed for product '{product_name}' is zero.\")\n",
    "            return None\n",
    "\n",
    "        processing_hours = quantity_liters / effective_speed\n",
    "        processing_start = current_time\n",
    "        processing_end = current_time + timedelta(hours=processing_hours)\n",
    "\n",
    "        # If a wash happened immediately before this processing start, reset the 24h origin here\n",
    "        if reset_24h_on_next_processing:\n",
    "            last_processing_start_after_wash = processing_start\n",
    "            reset_24h_on_next_processing = False\n",
    "        elif last_processing_start_after_wash is None and i == 0:\n",
    "            # First product and no earlier wash — start the 24h timer from initial processing start\n",
    "            last_processing_start_after_wash = processing_start\n",
    "\n",
    "        # === Build wash interruptions robustly ===\n",
    "        wash_interruptions = []\n",
    "\n",
    "        while True:\n",
    "            added_any = False\n",
    "            # current window end = processing_end + sum(wash durations already added)\n",
    "            window_end = processing_end + timedelta(hours=total_extension_hours(wash_interruptions))\n",
    "\n",
    "            # Add scheduled washes that start before the current window end\n",
    "            while next_scheduled_wash and next_scheduled_wash < window_end:\n",
    "                wash_end = next_scheduled_wash + wash_duration\n",
    "                wash_interruptions.append({\n",
    "                    'start': next_scheduled_wash,\n",
    "                    'end': wash_end,\n",
    "                    'type': 'scheduled'\n",
    "                })\n",
    "                next_scheduled_wash = wash_end + gap_duration\n",
    "                added_any = True\n",
    "\n",
    "            # Recompute window_end after scheduled washes\n",
    "            window_end = processing_end + timedelta(hours=total_extension_hours(wash_interruptions))\n",
    "\n",
    "            # Check standalone 24h intermediate (origin is last_processing_start_after_wash)\n",
    "            if last_processing_start_after_wash:\n",
    "                standalone_due = last_processing_start_after_wash + timedelta(hours=24)\n",
    "                \n",
    "                if processing_start <= standalone_due <= window_end:\n",
    "                    # Make sure there's no intermediate already before the standalone_due\n",
    "                    has_intermediate_in_period = any(\n",
    "                        (w['start'] >= last_processing_start_after_wash and w['start'] <= standalone_due)\n",
    "                        for w in wash_interruptions\n",
    "                    )\n",
    "                    \n",
    "                    if not has_intermediate_in_period:\n",
    "                        wash_interruptions.append({\n",
    "                            'start': standalone_due,\n",
    "                            'end': standalone_due + intermediate_duration,\n",
    "                            'type': 'standalone_intermediate'\n",
    "                        })\n",
    "                        added_any = True\n",
    "\n",
    "            if not added_any:\n",
    "                break\n",
    "\n",
    "        # Sort interruptions\n",
    "        wash_interruptions.sort(key=lambda x: x['start'])\n",
    "\n",
    "        # Total extension due to washes that fall after processing_start\n",
    "        total_wash_extension = sum(\n",
    "            (w['end'] - w['start']).total_seconds() / 3600.0\n",
    "            for w in wash_interruptions\n",
    "            if w['start'] >= processing_start\n",
    "        )\n",
    "\n",
    "        extended_processing_end = processing_end + timedelta(hours=total_wash_extension)\n",
    "\n",
    "        # Add wash tasks and mark that a wash resets the 24hr clock\n",
    "        for wash in wash_interruptions:\n",
    "            if wash['type'] == 'scheduled':\n",
    "                tasks.append({\n",
    "                    'start': wash['start'],\n",
    "                    'end': wash['end'],\n",
    "                    'task': 'wash',\n",
    "                    'product': 'Scheduled Wash',\n",
    "                    'order': -2\n",
    "                })\n",
    "                tasks.append({\n",
    "                    'start': wash['start'],\n",
    "                    'end': wash['end'],\n",
    "                    'task': 'intermediate_wash',\n",
    "                    'product': 'Intermediate Wash',\n",
    "                    'order': -1\n",
    "                })\n",
    "                last_wash_end_time = wash['end']\n",
    "                reset_24h_on_next_processing = True\n",
    "            elif wash['type'] == 'standalone_intermediate':\n",
    "                tasks.append({\n",
    "                    'start': wash['start'],\n",
    "                    'end': wash['end'],\n",
    "                    'task': 'intermediate_wash',\n",
    "                    'product': 'Intermediate Wash',\n",
    "                    'order': -1\n",
    "                })\n",
    "                last_wash_end_time = wash['end']\n",
    "                reset_24h_on_next_processing = True\n",
    "\n",
    "        # Create processing segments around washes\n",
    "        segment_start = processing_start\n",
    "        for wash in wash_interruptions:\n",
    "            if segment_start < wash['start']:\n",
    "                tasks.append({\n",
    "                    'start': segment_start,\n",
    "                    'end': wash['start'],\n",
    "                    'task': 'processing',\n",
    "                    'product': product_name,\n",
    "                    'order': i\n",
    "                })\n",
    "            # processing resumes after the wash with 1 minute buffer\n",
    "            segment_start = max(segment_start, wash['end'] + timedelta(minutes=1))\n",
    "\n",
    "        # Final processing segment\n",
    "        if segment_start < extended_processing_end:\n",
    "            tasks.append({\n",
    "                'start': segment_start,\n",
    "                'end': extended_processing_end,\n",
    "                'task': 'processing',\n",
    "                'product': product_name,\n",
    "                'order': i\n",
    "            })\n",
    "\n",
    "        # Advance time to end of this product\n",
    "        current_time = extended_processing_end\n",
    "\n",
    "        # safer: reset 24h origin only when processing truly resumes after a wash\n",
    "        if wash_interruptions:\n",
    "            last_wash = max(wash_interruptions, key=lambda w: w['end'])\n",
    "            # ensure processing is resuming after that wash\n",
    "            if last_wash['end'] <= segment_start and last_wash.get('type') in ('scheduled', 'standalone_intermediate'):\n",
    "                last_processing_start_after_wash = segment_start\n",
    "                reset_24h_on_next_processing = False  # Clear the flag since we've handled the reset\n",
    "\n",
    "    # === Visualization ===\n",
    "    fig, ax = plt.subplots(figsize=(18, 8))\n",
    "    ax.set_facecolor('white')\n",
    "\n",
    "    if not tasks:\n",
    "        st.error(\"No tasks generated. Please check your data.\")\n",
    "        return None\n",
    "\n",
    "    tasks_df = pd.DataFrame(tasks)\n",
    "    wash_products = ['Scheduled Wash', 'Intermediate Wash']\n",
    "    other_products = [p for p in tasks_df['product'].unique() if p not in wash_products]\n",
    "    product_order = [p for p in wash_products if p in tasks_df['product'].unique()] + other_products\n",
    "\n",
    "    y_pos = 0\n",
    "    for product_name in product_order:\n",
    "        product_tasks = tasks_df[tasks_df['product'] == product_name].sort_values('start')\n",
    "\n",
    "        for _, task in product_tasks.iterrows():\n",
    "            duration = task['end'] - task['start']\n",
    "            ax.broken_barh(\n",
    "                [(task['start'], duration)],\n",
    "                (y_pos - 0.4, 0.8),\n",
    "                facecolors=colors[task['task']],\n",
    "                edgecolor='black'\n",
    "            )\n",
    "\n",
    "            # Time-only labels\n",
    "            if task['task'] in ['wash', 'intermediate_wash']:\n",
    "                ax.vlines(task['start'], ymin=-0.5, ymax=y_pos + 0.4,\n",
    "                        color='gray', linestyle='-', linewidth=0.5, alpha=0.5)\n",
    "                ax.vlines(task['end'], ymin=-0.5, ymax=y_pos + 0.4,\n",
    "                        color='gray', linestyle='-', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "                ax.text(task['start'], -0.1, task['start'].strftime('%H:%M'),\n",
    "                        rotation=90, va='top', ha='right', fontsize=8, fontweight='bold',\n",
    "                        color='black', path_effects=[matplotlib.patheffects.withStroke(linewidth=3, foreground='yellow')])\n",
    "                ax.text(task['end'], -0.1, task['end'].strftime('%H:%M'),\n",
    "                        rotation=90, va='top', ha='right', fontsize=8, fontweight='bold',\n",
    "                        color='black', path_effects=[matplotlib.patheffects.withStroke(linewidth=3, foreground='yellow')])\n",
    "\n",
    "            if task['task'] == 'processing':\n",
    "                ax.text(task['start'], y_pos + 0.5, task['start'].strftime('%H:%M'),\n",
    "                        rotation=90, va='bottom', ha='left', fontsize=7, fontweight='bold',\n",
    "                        color='black', path_effects=[matplotlib.patheffects.withStroke(linewidth=2, foreground='lightgreen')])\n",
    "                ax.text(task['end'], y_pos + 0.5, task['end'].strftime('%H:%M'),\n",
    "                        rotation=90, va='bottom', ha='left', fontsize=7, fontweight='bold',\n",
    "                        color='black', path_effects=[matplotlib.patheffects.withStroke(linewidth=2, foreground='lightgreen')])\n",
    "\n",
    "        y_pos += 1\n",
    "\n",
    "    # axes, grid, labels\n",
    "    ax.set_yticks(range(len(product_order)))\n",
    "    ax.set_yticklabels(product_order)\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    \n",
    "    # Create title with week information only\n",
    "    start_date = tasks_df['start'].min()\n",
    "    end_date = tasks_df['end'].max()\n",
    "    week_start = start_date.strftime('%Y-%m-%d')\n",
    "    week_end = end_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    title = f\"Weekly Production Plan Timeline\\nWeek: {week_start} to {week_end}\"\n",
    "    ax.set_title(title, fontsize=14, pad=20)\n",
    "    ax.grid(True)\n",
    "    \n",
    "    # Add timestamp at bottom left corner\n",
    "    current_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    ax.text(0.01, 0.02, f\"Generated: {current_timestamp}\", \n",
    "            transform=ax.transAxes, ha='left', va='bottom',\n",
    "            fontsize=9, alpha=0.7, style='italic',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # time formatting\n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%a %m-%d'))\n",
    "    ax.xaxis.set_minor_locator(mdates.HourLocator(interval=3))\n",
    "    ax.xaxis.set_minor_formatter(mdates.DateFormatter('%H:%M'))\n",
    "\n",
    "    first_date = tasks_df['start'].min().floor('D')\n",
    "    last_date = tasks_df['end'].max().ceil('D')\n",
    "    delta_days = (last_date - first_date).days + 1\n",
    "    for day in range(delta_days):\n",
    "        day_start = first_date + timedelta(days=day)\n",
    "        ax.axvline(day_start, color='gray', linestyle='--', linewidth=1, alpha=0.6)\n",
    "\n",
    "    plt.xticks(rotation=90, ha='right', va='top')\n",
    "    plt.setp(ax.get_xminorticklabels(), rotation=90, ha='right', va='top')\n",
    "\n",
    "    # Legend\n",
    "    handles = [plt.Rectangle((0, 0), 1, 1, fc=colors[t]) for t in colors]\n",
    "    ax.legend(handles, colors.keys(), loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"Production Plan Timeline Generator\", layout=\"wide\")\n",
    "    \n",
    "    st.title(\"Production Plan Timeline Generator\")\n",
    "    st.write(\"Upload your production plan file (Excel or CSV) to generate a timeline visualization.\")\n",
    "    \n",
    "    uploaded_file = st.file_uploader(\n",
    "        \"Choose a file\",\n",
    "        type=['xlsx', 'xls', 'csv'],\n",
    "        help=\"Upload an Excel or CSV file containing your production plan data.\"\n",
    "    )\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        try:\n",
    "            if uploaded_file.name.endswith('.csv'):\n",
    "                df = pd.read_csv(uploaded_file)\n",
    "            else:\n",
    "                df = pd.read_excel(uploaded_file)\n",
    "            \n",
    "            st.success(f\"File uploaded successfully: {uploaded_file.name}\")\n",
    "            \n",
    "            st.subheader(\"Data Preview\")\n",
    "            st.dataframe(df.head())\n",
    "            \n",
    "            required_columns = [\n",
    "                'product name', 'quantity liters', 'process speed per hour',\n",
    "                'line efficiency', 'Change Over', 'Date from', 'Duration', 'Gap'\n",
    "            ]\n",
    "            optional_columns = ['First Wash Time', 'Additional Wash']\n",
    "            \n",
    "            missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "            \n",
    "            if missing_columns:\n",
    "                st.error(f\"Missing required columns: {', '.join(missing_columns)}\")\n",
    "                st.write(\"**Required columns:**\")\n",
    "                for col in required_columns:\n",
    "                    status = \"✅\" if col in df.columns else \"❌\"\n",
    "                    st.write(f\"{status} {col}\")\n",
    "                st.write(\"**Optional columns:**\")\n",
    "                for col in optional_columns:\n",
    "                    status = \"✅\" if col in df.columns else \"⚪\"\n",
    "                    st.write(f\"{status} {col}\")\n",
    "            else:\n",
    "                st.success(\"All required columns found!\")\n",
    "                \n",
    "                for col in optional_columns:\n",
    "                    if col in df.columns:\n",
    "                        st.info(f\"Optional column '{col}' found - will be used.\")\n",
    "                    else:\n",
    "                        st.info(f\"Optional column '{col}' not found - defaults will be used.\")\n",
    "                \n",
    "                if st.button(\"Generate Timeline\", type=\"primary\"):\n",
    "                    with st.spinner(\"Generating timeline...\"):\n",
    "                        fig = generate_timeline(df)\n",
    "                        if fig:\n",
    "                            st.subheader(\"Production Timeline\")\n",
    "                            st.pyplot(fig)\n",
    "                            \n",
    "                            buf = io.BytesIO()\n",
    "                            fig.savefig(buf, format='png', bbox_inches='tight', dpi=300)\n",
    "                            buf.seek(0)\n",
    "                            \n",
    "                            st.download_button(\n",
    "                                label=\"Download Timeline as PNG\",\n",
    "                                data=buf.getvalue(),\n",
    "                                file_name=\"production_timeline.png\",\n",
    "                                mime=\"image/png\"\n",
    "                            )\n",
    "                        else:\n",
    "                            st.error(\"Failed to generate timeline. Please check your data format.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error reading file: {str(e)}\")\n",
    "    else:\n",
    "        st.info(\"Please upload a file to get started.\")\n",
    "        \n",
    "        with st.expander(\"Expected File Format\"):\n",
    "            st.write(\"Your file should contain these columns:\")\n",
    "            st.write(\"**Required:** product name, quantity liters, process speed per hour, line efficiency, Change Over, Date from, Duration, Gap\")\n",
    "            st.write(\"**Optional:** First Wash Time, Additional Wash\")\n",
    "            st.write(\"**Data Format:** All wash parameters (Duration, Gap, First Wash Time) should be in the first row.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
